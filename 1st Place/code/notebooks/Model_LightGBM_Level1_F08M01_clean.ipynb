{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# for reproducibility\"\n",
    "random_state = np.random.RandomState(2925)\n",
    "np.random.seed(2925) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_country_df(preds, test_feat, country):\n",
    "    # make sure we code the country correctly\n",
    "    country_codes = ['A', 'B', 'C']\n",
    "    \n",
    "    # get just the poor probabilities\n",
    "    country_sub = pd.DataFrame(data=preds, # proba p=1\n",
    "                               columns=['poor'], \n",
    "                               index=test_feat.index)\n",
    "\n",
    "    \n",
    "    # add the country code for joining later\n",
    "    country_sub[\"country\"] = country\n",
    "    return country_sub[[\"country\", \"poor\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modelA_v1(Xtr, Ytr, Xte):\n",
    "   \n",
    "    cat_list = list(Xtr.select_dtypes(include=['object', 'bool']).columns)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    for col in cat_list:\n",
    "        le.fit(np.concatenate((Xtr[col].values, Xte[col].values), axis=0))\n",
    "        Xtr[col] = pd.Categorical(le.transform(Xtr[col].values))\n",
    "        Xte[col] = pd.Categorical(le.transform(Xte[col].values))\n",
    "\n",
    "    # create dataset for lightgbm\n",
    "    lgb_train = lgb.Dataset(Xtr,\n",
    "                      label=Ytr,\n",
    "                     feature_name=list(Xtr.columns),\n",
    "                      categorical_feature=cat_list) \n",
    "                                \n",
    "    # specify your configurations as a dict\n",
    "    params = {\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric': {'binary_logloss'},\n",
    "        'num_leaves': 43,\n",
    "        'max_depth':16,\n",
    "        'min_data_in_leaf': 16,\n",
    "        'feature_fraction': 0.75,\n",
    "        'bagging_fraction': 0.56,\n",
    "        'bagging_freq': 1,\n",
    "        'lambda_l2':0.0, \n",
    "        'verbose' : 0,\n",
    "        'seed':1,\n",
    "        'learning_rate': 0.004,\n",
    "\n",
    "    }\n",
    "\n",
    "    # train\n",
    "    gbm = lgb.train(params, lgb_train, categorical_feature=cat_list, num_boost_round=3200)\n",
    "\n",
    "    Yt = gbm.predict(Xte)\n",
    "    return Yt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_paths = {'A': {'train_hhold': 'data/A_hhold_train.csv', \n",
    "                        'test_hhold':  'data/A_hhold_test.csv',\n",
    "                        'train_indiv': 'data/A_indiv_train.csv', \n",
    "                        'test_indiv':  'data/A_indiv_test.csv'}, \n",
    "\n",
    "                  'B': {'train_hhold': 'data/B_hhold_train.csv', \n",
    "                        'test_hhold':  'data/B_hhold_test.csv',\n",
    "                        'train_indiv': 'data/B_indiv_train.csv', \n",
    "                        'test_indiv':  'data/B_indiv_test.csv'}, \n",
    "\n",
    "                  'C': {'train_hhold': 'data/C_hhold_train.csv', \n",
    "                        'test_hhold':  'data/C_hhold_test.csv',\n",
    "                        'train_indiv': 'data/C_indiv_train.csv', \n",
    "                        'test_indiv':  'data/C_indiv_test.csv'}}\n",
    "\n",
    "def get_cat_summary_choose(data_hhold, data_indiv, which='max', which_var=[], traintest=None):\n",
    "    var2drop = []\n",
    "    if traintest=='train':\n",
    "        var2drop = ['iid', 'poor', 'country']\n",
    "    elif traintest=='test':\n",
    "        var2drop = ['iid', 'country']\n",
    "    varobj = which_var\n",
    "    df = pd.DataFrame(index = data_hhold.index)\n",
    "    for s in varobj:\n",
    "        if which=='max':\n",
    "            df_s = pd.get_dummies(data_indiv[s]).groupby('id').max()\n",
    "        elif which=='min':\n",
    "            df_s = pd.get_dummies(data_indiv[s]).groupby('id').min()\n",
    "        else:\n",
    "            print('Not a valid WHICH')\n",
    "        df = df.merge(df_s, left_index=True, right_index=True, suffixes=['', s+'_'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features(Country='A', f_dict=None, traintest='train'):\n",
    "      \n",
    "    # load data\n",
    "    data_hhold = pd.read_csv(data_paths[Country]['%s_hhold' % traintest], index_col='id')\n",
    "    data_indiv = pd.read_csv(data_paths[Country]['%s_indiv' % traintest], index_col='id')\n",
    "\n",
    "    ## Add indiv features:\n",
    "    if f_dict.get('cat_hot'):\n",
    "        df = get_cat_summary_choose(data_hhold, data_indiv, which='min',\n",
    "                             which_var = f_dict.get('cat_hot_which'),\n",
    "                             traintest=traintest)\n",
    "        data_hhold = data_hhold.merge(df, left_index=True, right_index=True)\n",
    "        \n",
    "        df = get_cat_summary_choose(data_hhold, data_indiv, which='max',\n",
    "                             which_var = f_dict.get('cat_hot_which'),\n",
    "                             traintest=traintest)\n",
    "        data_hhold = data_hhold.merge(df, left_index=True, right_index=True)\n",
    "        \n",
    "    \n",
    "    return data_hhold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pre_process_data(df, enforce_cols=None):\n",
    "    \n",
    "    df.drop([\"country\"], axis=1, inplace=True)\n",
    "    # match test set and training set columns\n",
    "    if enforce_cols is not None:\n",
    "        to_drop = np.setdiff1d(df.columns, enforce_cols)\n",
    "        to_add = np.setdiff1d(enforce_cols, df.columns)\n",
    "\n",
    "        df.drop(to_drop, axis=1, inplace=True)\n",
    "        df = df.assign(**{c: 0 for c in to_add})\n",
    "    \n",
    "    df.fillna(df.mean(), inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_test_train_v2():\n",
    "\n",
    "    feat = dict()\n",
    "    feat['A'] = dict()\n",
    "    feat['A']['cat_hot'] = True\n",
    "    feat['A']['cat_hot_which'] =  ['CaukPfUC', 'MUrHEJeh', 'MzEtIdUF', 'XizJGmbu', 'rQWIpTiG']\n",
    "        \n",
    "    a_train = get_features(Country='A', f_dict=feat['A'], traintest='train')  \n",
    "    a_test = get_features(Country='A', f_dict=feat['A'], traintest='test')  \n",
    "       \n",
    "    print(\"Country A\")\n",
    "    aX_train = pre_process_data(a_train.drop('poor', axis=1))\n",
    "    ay_train = np.ravel(a_train.poor)\n",
    "\n",
    "\n",
    "    # process the test data\n",
    "    aX_test = pre_process_data(a_test, enforce_cols=aX_train.columns)\n",
    "\n",
    "    aremove_list = ['sDGibZrP', 'RMbjnrlm', 'GUvFHPNA', 'iwkvfFnL', 'goxNwvnG', 'HDMHzGif', 'MOIscfCf',\n",
    "                    'tOWnWxYe', 'CtFxPQPT', 'fsXLyyco', 'ztGMreNV', 'YDgWYWcJ', 'pQmBvlkz', 'RLKqBexO', \n",
    "                    'BwkgSxCk', 'rfDBJtIz', 'cOSBrarW', 'lRGpWehf', 'dSALvhyd', 'WbxAxHul', 'NitzgUzY', \n",
    "                    'bhFgAObo', 'mnIQKNOM', 'GYTJWlaF', 'lTAXSTys', 'IBPMYJlv', 'WbEDLWBH', 'cgJgOfCA', \n",
    "                    'hTraVEWP', 'nKoaotpH', 'OnTaJkLa', 'EMDSHIlJ', 'NGOnRdqc', 'vmZttwFZ', 'tjrOpVkX', \n",
    "                    'zXPyHBkn', 'dkoIJCbY', 'hJrMTBVd', 'xNUUjCIL', 'rnJOTwVD', 'dAaIakDk', 'WqhniYIc', \n",
    "                    'HfOrdgBo', 'wBXbHZmp', 'FGYOIJbC', 'CbzSWtkF', 'TzPdCEPV', 'lybuQXPm', 'GDUPaBQs',\n",
    "                    'EfkPrfXa', 'JeydMEpC', 'jxSUvflR', 'VFTkSOrq', 'CpqWSQcW', 'iVscWZyL', 'JMNvdasy', \n",
    "                    'NrvxpdMQ', 'nGMEgWyl', 'pyBSpOoN', 'zvjiUrCR', 'aCfsveTu', 'TvShZEBA', 'TJUYOoXU', \n",
    "                    'sYIButva', 'cWNZCMRB', 'yeHQSlwg', 'nSzbETYS', 'CVCsOVew', 'UXSJUVwD', 'FcekeISI', \n",
    "                    'QBJeqwPF', 'mBlWbDmc', 'MBQcYnjc', 'KHzKOKPw', 'LrDrWRjC', 'TFrimNtw', 'InULRrrv', \n",
    "                    'fhKiXuMY', 'fxbqfEWb', 'GnUDarun', 'XVwajTfe', 'yHbEDILT', 'JbjHTYUM', 'mHzqKSuN',\n",
    "                    'ncjMNgfp', 'dkPWxwSF', 'dsIjcEFe', 'ySkAFOzx', 'QzqNzAJE', 'bgfNZfcj', 'tZKoAqgl', \n",
    "                    'NrUWfvEq', 'SsZAZLma', 'mNrEOmgq', 'hESBInAl', 'ofhkZaYa', 'mDTcQhdH', 'mvGdZZcs', \n",
    "                    'ALbGNqKm', 'wgWdGBOp', 'nuwxPLMe', 'vRIvQXtC', 'rAkSnhJF', 'rtPrBBPl', 'tMJrvvut', \n",
    "                    'BbKZUYsB', 'LjvKYNON', 'uZGqTQUP', 'NIRMacrk', 'UBanubTh', 'dEpQghsA', 'WiwmbjGW', \n",
    "                    'ULMvnWcn', 'AsEmHUzj', 'BMmgMRvd', 'QqoiIXtI', 'duayPuvk', 'YKwvJgoP', 'ytYMzOlW',\n",
    "                    'YXkrVgqt', 'sslNoPlw', 'IIEHQNUc', 'ErggjCIN', 'tlxXCDiW', 'eeYoszDM', 'KAJOWiiw', \n",
    "                    'UCnazcxd', 'uVnApIlJ', 'ZzUrQSMj', 'nGTepfos', 'ogHwwdzc', 'eoNxXdlZ', 'kZVpcgJL', \n",
    "                    'lFcfBRGd', 'UXhTXbuS', 'UsENDgsH', 'wxDnGIwN', 'rYvVKPAF', 'OybQOufM', 'wnESwOiN', \n",
    "                    'glEjrMIg', 'iBQXwnGC', 'VBjVVDwp', 'lOujHrCk', 'wakWLjkG', 'RJFKdmYJ', 'ZmJZXnoA', \n",
    "                    'lQQeVmCa', 'ihGjxdDj', 'mycoyYwl', 'FlBqizNL', 'CIGUXrRQ', 'YlZCqMNw', 'gllMXToa',\n",
    "                    'DbUNVFwv', 'EuJrVjyG', 'uRFXnNKV', 'gfmfEyjQ', 'ggNglVqE']    \n",
    "\n",
    "    \n",
    "    aX_train.drop(aremove_list, axis=1, inplace=True)\n",
    "    aX_test.drop(aremove_list, axis=1, inplace=True)\n",
    "    \n",
    "    print(\"--------------------------------------------\")\n",
    "    return aX_train,ay_train, aX_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country A\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "aX_train, aY_train, aX_test = read_test_train_v2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Train/Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = {'A':'modelA_v1'}\n",
    "\n",
    "datafiles = {}\n",
    "datafiles['out'] = 'predictions/Light_M01_F08_'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_preds = eval(model['A'])(aX_train, aY_train, aX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert preds to data frames\n",
    "a_sub = make_country_df(a_preds.flatten(), aX_test, 'A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_sub.to_csv(datafiles['out'] + '_A_test.csv')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
