{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "random_state = np.random.RandomState(2925)\n",
    "np.random.seed(2925) # for reproducibility\"\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import  LabelEncoder\n",
    "\n",
    "from keras.regularizers import l2,l1\n",
    "from keras.layers import Input, Embedding, Dense, Dropout, Flatten\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Lambda\n",
    "from keras import backend as K\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras.layers.advanced_activations import PReLU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_country_df(preds, test_feat, country):\n",
    "    # make sure we code the country correctly\n",
    "    country_codes = ['A', 'B', 'C']\n",
    "    \n",
    "    # get just the poor probabilities\n",
    "    country_sub = pd.DataFrame(data=preds,  # proba p=1\n",
    "                               columns=['poor'], \n",
    "                               index=test_feat.index)\n",
    "\n",
    "    \n",
    "    # add the country code for joining later\n",
    "    country_sub[\"country\"] = country\n",
    "    return country_sub[[\"country\", \"poor\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next feature transformations were inspired by this post: [link](https://medium.com/airbnb-engineering/overcoming-missing-values-in-a-random-forest-classifier-7b1fc1fc03ba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_Fx_numeric(x_train, x_test, y_train):\n",
    "    x_train_nonmissing_loc = (x_train != -1212121)\n",
    "    x_test_nonmissing_loc = (x_test != -1212121)\n",
    "    x_train_nonmissing = x_train[x_train_nonmissing_loc] \n",
    "    x_test_nonmissing = x_test[x_test_nonmissing_loc]\n",
    "    \n",
    "    y_train_nonmissing = y_train[x_train_nonmissing_loc]\n",
    "    y_train_nonmissing_ones = (y_train_nonmissing == True)\n",
    "    x_train_nonmissing_ones = x_train_nonmissing[y_train_nonmissing_ones]\n",
    "    \n",
    "    prob_train = [round(stats.percentileofscore(x_train_nonmissing_ones, a, 'weak')/100.,2) for a in x_train_nonmissing]\n",
    "    prob_test = [round(stats.percentileofscore(x_train_nonmissing_ones, a, 'weak')/100.,2) for a in x_test_nonmissing]\n",
    "    \n",
    "    Fx_train = np.array(x_train[:], dtype=float)\n",
    "    Fx_test = np.array(x_test[:], dtype=float)\n",
    "    Fx_train[x_train_nonmissing_loc]=prob_train\n",
    "    Fx_test[x_test_nonmissing_loc]=prob_test\n",
    "    return Fx_train, Fx_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def expand_dims(x):\n",
    "    return K.expand_dims(x, 1)\n",
    "\n",
    "def expand_dims_output_shape(input_shape):\n",
    "    return (input_shape[0], 1, input_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "def standardize(df, numeric_only=True):\n",
    "    numeric = df.select_dtypes(include=['int64', 'float64'])\n",
    "    # subtracy mean and divide by std\n",
    "    df[numeric.columns] = (numeric - numeric.mean()) / numeric.std()\n",
    "    return df\n",
    "\n",
    "\n",
    "def keras_encoding(df_train,df_test):\n",
    "\n",
    "    ntrain = df_train.shape[0]\n",
    "    df_all = pd.concat((df_train, df_test), axis=0, ignore_index=True)\n",
    "    \n",
    "    num_list = list(df_train.select_dtypes(include=['int64', 'float64']).columns)\n",
    "    df_all = standardize(df_all)\n",
    "    \n",
    "    cat_list = list(df_train.select_dtypes(include=['object', 'bool']).columns)\n",
    "    for c in cat_list:\n",
    "        df_all[c] = df_all[c].astype('category').cat.as_ordered()\n",
    "        \n",
    "    le = LabelEncoder()\n",
    "\n",
    "    for col in cat_list:\n",
    "        le.fit(df_all[col].values)\n",
    "        df_all[col] = le.transform(df_all[col].values)\n",
    "\n",
    "    Din = dict()\n",
    "    Dout = dict()   \n",
    "    for col in cat_list:\n",
    "        cat_sz = np.size(np.unique(df_all[col].values))\n",
    "        Din[col]= cat_sz\n",
    "        Dout[col] = max(3,min(50, (cat_sz+1)//2))\n",
    "    \n",
    "    df_train = df_all.iloc[:ntrain,:].copy()\n",
    "    df_test = df_all.iloc[ntrain:,:].copy()\n",
    "    return df_train,df_test, num_list, cat_list, Din, Dout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Keras_A01(Xtr,Ytr,Xte,num_list, cat_list, Din, Dout,cv_i):\n",
    "\n",
    "    X_list = []\n",
    "    for col in cat_list:\n",
    "        X_list.append(Xtr[col].values)\n",
    "    X_list.append(Xtr[num_list].values)\n",
    "    X_train = X_list\n",
    "    X_list = []\n",
    "    for col in cat_list:\n",
    "        X_list.append(Xte[col].values)\n",
    "    X_list.append(Xte[num_list].values)\n",
    "    X_test = X_list\n",
    "    l2_emb = 0.0001\n",
    "\n",
    "    #emb_layers=[]\n",
    "    cat_out = []\n",
    "    cat_in = []\n",
    "\n",
    "    #cat var\n",
    "    for idx, var_name in enumerate(cat_list):\n",
    "        x_in = Input(shape=(1,), dtype='int64', name=var_name+'_in')\n",
    "\n",
    "        input_dim = Din[var_name]\n",
    "        output_dim = Dout[var_name]\n",
    "        x_out = Embedding(input_dim, \n",
    "                          output_dim, \n",
    "                          input_length=1, \n",
    "                          name = var_name, \n",
    "                          embeddings_regularizer=l1(l2_emb))(x_in)\n",
    "\n",
    "        flatten_c = Flatten()(x_out)\n",
    "        #emb_layers.append(x_out) \n",
    "        \n",
    "        cat_in.append(x_in)\n",
    "        cat_out.append(flatten_c)  \n",
    "\n",
    "    x_emb = layers.concatenate(cat_out,name = 'emb')\n",
    "\n",
    "    #continuous variables\n",
    "    cont_in = Input(shape=(len(num_list),), name='continuous_input')\n",
    "    cont_out = Lambda(expand_dims, expand_dims_output_shape)(cont_in)\n",
    "    x_num = Flatten(name = 'num')(cont_out)\n",
    "\n",
    "    cat_in.append(cont_in)\n",
    "\n",
    "    #merge\n",
    "    x = layers.concatenate([x_emb,x_num],name = 'emb_num')\n",
    "    x = Dense(512)(x)\n",
    "    x = PReLU()(x)\n",
    "    x = Dropout(0.6)(x)\n",
    "    x = Dense(64)(x)\n",
    "    x = PReLU()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(32)(x)\n",
    "    x = PReLU()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "\n",
    "    model = Model(inputs = cat_in, outputs = x)\n",
    "    \n",
    "    model.compile(optimizers.Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(X_train, Ytr, batch_size=256, epochs=9,verbose=0,shuffle=True)\n",
    " \n",
    "    Yt = model.predict(X_test).flatten() \n",
    "    K.clear_session()\n",
    "    return Yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_generator(X, y,cat_list,num_list,batch_size):\n",
    "    \n",
    "    n_splits = X.shape[0] // (batch_size - 1)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits,random_state=2925, shuffle=True)\n",
    "\n",
    "    while True:\n",
    "        for idx_tr, idx_te in skf.split(X, y):\n",
    "            X_batch = X.iloc[idx_te].reset_index(drop=True).copy()\n",
    "            y_batch = y[idx_te]\n",
    "        \n",
    "            X_list = []\n",
    "            for col in cat_list:\n",
    "                X_list.append(X_batch[col].values)\n",
    "            X_list.append(X_batch[num_list].values)\n",
    "            X_batch = X_list    \n",
    "\n",
    "            yield (X_batch, y_batch)\n",
    "\n",
    "\n",
    "def Keras_C01(Xtr,Ytr,Xte,num_list, cat_list, Din, Dout,cv_i):\n",
    "    X_list = []\n",
    "    for col in cat_list:\n",
    "        X_list.append(Xtr[col].values)\n",
    "    X_list.append(Xtr[num_list].values)\n",
    "    X_train = X_list\n",
    "    \n",
    "    X_list = []\n",
    "    for col in cat_list:\n",
    "        X_list.append(Xte[col].values)\n",
    "    X_list.append(Xte[num_list].values)\n",
    "    X_test = X_list\n",
    "\n",
    "    l2_emb = 0.0001\n",
    "\n",
    "    #emb_layers=[]\n",
    "    cat_out = []\n",
    "    cat_in = []\n",
    "\n",
    "    #cat var\n",
    "    for idx, var_name in enumerate(cat_list):\n",
    "        x_in = Input(shape=(1,), dtype='int64', name=var_name+'_in')\n",
    "\n",
    "        input_dim = Din[var_name]\n",
    "        output_dim = Dout[var_name]\n",
    "        x_out = Embedding(input_dim, \n",
    "                          output_dim, \n",
    "                          input_length=1, \n",
    "                          name = var_name, \n",
    "                          embeddings_regularizer=l1(l2_emb))(x_in)\n",
    "\n",
    "        flatten_c = Flatten()(x_out)\n",
    "        #emb_layers.append(x_out) \n",
    "        \n",
    "        cat_in.append(x_in)\n",
    "        cat_out.append(flatten_c)  \n",
    "        \n",
    "    x_emb = layers.concatenate(cat_out,name = 'emb')\n",
    "\n",
    "    #continuous variables\n",
    "    cont_in = Input(shape=(len(num_list),), name='continuous_input')\n",
    "    cont_out = Lambda(expand_dims, expand_dims_output_shape)(cont_in)\n",
    "    x_num = Flatten(name = 'num')(cont_out)\n",
    "\n",
    "    cat_in.append(cont_in)\n",
    "\n",
    "    #merge\n",
    "    x = layers.concatenate([x_emb,x_num],name = 'emb_num')\n",
    "    x = Dense(512)(x)\n",
    "    x = PReLU()(x)\n",
    "    x = Dropout(0.6)(x)\n",
    "    x = Dense(64)(x)\n",
    "    x = PReLU()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(32)(x)\n",
    "    x = PReLU()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs = cat_in, outputs = x)\n",
    "    \n",
    "    model.compile(optimizers.Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    batch_size = 256\n",
    "    model.fit_generator(generator=batch_generator(Xtr, Ytr,cat_list,num_list, batch_size),\n",
    "                    epochs=9, verbose=0, steps_per_epoch= np.floor(Xtr.shape[0]/batch_size))\n",
    "\n",
    "    Yt = model.predict(X_test).flatten()\n",
    "    K.clear_session()\n",
    "    return Yt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pre_process_data(df, enforce_cols=None):\n",
    "    #print(\"Input shape:\\t{}\".format(df.shape))\n",
    "    df.drop([\"country\"], axis=1, inplace=True)\n",
    "\n",
    "    # match test set and training set columns\n",
    "    if enforce_cols is not None:\n",
    "        to_drop = np.setdiff1d(df.columns, enforce_cols)\n",
    "        to_add = np.setdiff1d(enforce_cols, df.columns)\n",
    "\n",
    "        df.drop(to_drop, axis=1, inplace=True)\n",
    "        df = df.assign(**{c: 0 for c in to_add})\n",
    "    \n",
    "    df.fillna(df.mean(), inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_paths = {'A': {'train_hhold': 'data/A_hhold_train.csv', \n",
    "                        'test_hhold':  'data/A_hhold_test.csv',\n",
    "                        'train_indiv': 'data/A_indiv_train.csv', \n",
    "                        'test_indiv':  'data/A_indiv_test.csv'}, \n",
    "\n",
    "                  'B': {'train_hhold': 'data/B_hhold_train.csv', \n",
    "                        'test_hhold':  'data/B_hhold_test.csv',\n",
    "                        'train_indiv': 'data/B_indiv_train.csv', \n",
    "                        'test_indiv':  'data/B_indiv_test.csv'}, \n",
    "\n",
    "                  'C': {'train_hhold': 'data/C_hhold_train.csv', \n",
    "                        'test_hhold':  'data/C_hhold_test.csv',\n",
    "                        'train_indiv': 'data/C_indiv_train.csv', \n",
    "                        'test_indiv':  'data/C_indiv_test.csv'}}\n",
    "\n",
    "\n",
    "def get_hhold_size(data_indiv):\n",
    "    return data_indiv.groupby('id').country.agg({'hhold_size':'count'})\n",
    "\n",
    "\n",
    "def get_num_mean(data_indiv, traintest=None):\n",
    "    var2drop = []\n",
    "    if traintest=='train':\n",
    "        var2drop = ['iid', 'poor']\n",
    "    elif traintest=='test':\n",
    "        var2drop = ['iid']\n",
    "    return data_indiv.drop(var2drop, axis=1).groupby('id').mean()\n",
    "\n",
    "def get_num_summary(data_indiv, which=None, traintest=None):\n",
    "    var2drop = []\n",
    "    if traintest=='train':\n",
    "        var2drop = ['iid', 'poor']\n",
    "    elif traintest=='test':\n",
    "        var2drop = ['iid']\n",
    " \n",
    "    aux = ~data_indiv.drop(var2drop, axis=1).dtypes.isin(['object','bool', 'O'])\n",
    "    varnum = [aux.keys()[i] for i,j in enumerate(aux) if aux.values[i]]\n",
    "\n",
    "    data_num_max = data_indiv[varnum].groupby('id').max()\n",
    "    \n",
    "    if which=='max':\n",
    "        ans = data_indiv[varnum].groupby('id').max()\n",
    "    elif  which=='min':\n",
    "        ans = data_indiv[varnum].groupby('id').min()\n",
    "    return ans\n",
    "\n",
    "\n",
    "def get_cat_summary_choose(data_hhold, data_indiv, which='max', which_var=[], traintest=None):\n",
    "    var2drop = []\n",
    "    if traintest=='train':\n",
    "        var2drop = ['iid', 'poor', 'country']\n",
    "    elif traintest=='test':\n",
    "        var2drop = ['iid', 'country']\n",
    "\n",
    "    varobj = which_var\n",
    "    df = pd.DataFrame(index = data_hhold.index)\n",
    "    for s in varobj:\n",
    "        #print(s)\n",
    "        if which=='max':\n",
    "            df_s = pd.get_dummies(data_indiv[s]).groupby('id').max()\n",
    "        elif which=='min':\n",
    "            df_s = pd.get_dummies(data_indiv[s]).groupby('id').min()\n",
    "        else:\n",
    "            print('Not a valid WHICH')\n",
    "        #print(df_s.keys())\n",
    "        df = df.merge(df_s, left_index=True, right_index=True, suffixes=['', s+'_'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_features(Country='A', f_dict=None, traintest='train'):\n",
    "      \n",
    "    # load data\n",
    "    data_hhold = pd.read_csv(data_paths[Country]['%s_hhold' % traintest], index_col='id')\n",
    "    data_indiv = pd.read_csv(data_paths[Country]['%s_indiv' % traintest], index_col='id')\n",
    "\n",
    "    varobj = data_indiv.select_dtypes('object', 'bool').columns\n",
    "\n",
    "    ## Add indiv features:\n",
    "    #hhold size\n",
    "    if f_dict.get('hh_size'):\n",
    "        data_hh_size = get_hhold_size(data_indiv)\n",
    "        data_hhold = data_hhold.merge(data_hh_size, left_index=True, right_index=True)\n",
    "    ## mean of numerical\n",
    "    if f_dict.get('num_mean'):\n",
    "        data_num_mean = get_num_mean(data_indiv, traintest=traintest)\n",
    "        data_hhold = data_hhold.merge(data_num_mean, left_index=True, right_index=True)\n",
    "   \n",
    "    # max of numerical\n",
    "    if f_dict.get('num_max'):\n",
    "        data_num_max = get_num_summary(data_indiv, which='max', traintest=traintest)\n",
    "        data_hhold = data_hhold.merge(data_num_max, left_index=True, right_index=True, suffixes=['', '_max'])\n",
    "   \n",
    "    # min of numerical\n",
    "    if f_dict.get('num_min'):\n",
    "        data_num_min = get_num_summary(data_indiv, which='min', traintest=traintest)\n",
    "        data_hhold = data_hhold.merge(data_num_min, left_index=True, right_index=True, suffixes=['', '_min'])\n",
    "       \n",
    "    if f_dict.get('cat_hot'):\n",
    "        df = get_cat_summary_choose(data_hhold, data_indiv, which='min',\n",
    "                             which_var = varobj,\n",
    "                             traintest=traintest)\n",
    "        df = df.add_suffix('_ind')\n",
    "        data_hhold = data_hhold.merge(df, left_index=True, right_index=True)\n",
    "\n",
    "        df = get_cat_summary_choose(data_hhold, data_indiv, which='max',\n",
    "                             which_var = varobj,\n",
    "                             traintest=traintest)\n",
    "        df = df.add_suffix('_ind')\n",
    "        data_hhold = data_hhold.merge(df, left_index=True, right_index=True)\n",
    "        \n",
    "    return data_hhold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_test_train_v2():\n",
    "\n",
    "    feat = dict()\n",
    "    feat['A'] = dict()\n",
    "    feat['A']['hh_size'] = True\n",
    "    feat['A']['num_mean'] = True\n",
    "    feat['A']['num_max'] = True\n",
    "    feat['A']['num_min'] = True\n",
    "    feat['A']['cat_hot'] = True\n",
    "    feat['A']['cat_hot_which'] =  []\n",
    "    \n",
    "    a_train = get_features(Country='A', f_dict=feat['A'], traintest='train')  \n",
    "    a_test = get_features(Country='A', f_dict=feat['A'], traintest='test')  \n",
    "   \n",
    "    \n",
    "    #feat = dict()\n",
    "    feat['C'] = dict()\n",
    "    feat['C']['hh_size'] = True\n",
    "    feat['C']['num_mean'] = True\n",
    "    feat['C']['num_max'] = True\n",
    "    feat['C']['num_min'] = True\n",
    "    feat['C']['cat_hot'] = True\n",
    "    feat['C']['cat_hot_which'] = []\n",
    "\n",
    "    c_train = get_features(Country='C', f_dict=feat['C'], traintest='train')  \n",
    "    c_test = get_features(Country='C', f_dict=feat['C'], traintest='test')  \n",
    "\n",
    "    print(\"Country A\")\n",
    "    aX_train = pre_process_data(a_train.drop('poor', axis=1))\n",
    "    ay_train = np.ravel(a_train.poor).astype(np.int8)\n",
    "\n",
    "    print(\"\\nCountry C\")\n",
    "    cX_train = pre_process_data(c_train.drop('poor', axis=1))\n",
    "    cy_train = np.ravel(c_train.poor).astype(np.int8)\n",
    "\n",
    "    # process the test data\n",
    "    aX_test = pre_process_data(a_test, enforce_cols=aX_train.columns)\n",
    "    cX_test = pre_process_data(c_test, enforce_cols=cX_train.columns)\n",
    "    \n",
    "    Afeatures = ['SlDKnCuu','maLAYXwi', 'vwpsXRGk', 'TYhoEiNm', 'zFkComtB', 'zzwlWZZC', 'DxLvCGgv', \n",
    "                 'CbABToOI', 'uSKnVaKV', 'nzTeWUeM', 'nEsgxvAq', 'NmAVTtfA', 'YTdCRVJt', 'QyBloWXZ', \n",
    "                 'HKMQJANN', 'ZRrposmO', 'HfKRIwMb', 'UCAmikjV', 'uJYGhXqG', 'bxKGlBYX', 'nCzVgxgY', \n",
    "                 'ltcNxFzI', 'MxOgekdE', 'JwtIxvKg', 'bEPKkJXP', 'cqUmYeAp', 'sFWbFEso', 'TqrXZaOw', \n",
    "                 'galsfNtg', 'VIRwrkXp', 'gwhBRami', 'bPOwgKnT', 'fpHOwfAs', 'VXXLUaXP', 'btgWptTG', \n",
    "                 'YWwNfVtR', 'bgoWYRMQ', 'bMudmjzJ', 'OMtioXZZ', 'bIBQTaHw', 'KcArMKAe', 'wwfmpuWA', \n",
    "                 'znHDEHZP', 'kWFVfHWP', 'XwVALSPR', 'HHAeIHna', 'dCGNTMiG', 'ngwuvaCV', 'XSgHIFXD', \n",
    "                 'ANBCxZzU', 'NanLCXEI', 'ZnBLVaqz', 'srPNUgVy', 'pCgBHqsR', 'wEbmsuJO', 'pWyRKfsb',\n",
    "                 'udzhtHIr', 'IZFarbPw', 'lnfulcWk', 'QNLOXNwj', 'YFMZwKrU', 'RJQbcmKy', 'uizuNzbk', \n",
    "                 'dlyiMEQt', 'TnWhKowI', 'LoYIbglA', 'GhJKwVWC', 'lVHmBCmb', 'qgxmqJKa', 'gfurxECf', \n",
    "                 'hnrnuMte', 'LrQXqVUj', 'XDDOZFWf', 'QayGNSmS', 'ePtrWTFd', 'tbsBPHFD', 'naDKOzdk', \n",
    "                 'xkUFKUoW', 'jVDpuAmP', 'SeZULMCT', 'AtGRGAYi', 'WTFJilSZ', 'NBfffJUe', 'mvgxfsRb', \n",
    "                 'UXfyiodk', 'EftwspgZ', 'szowPwNq', 'BfGjiYom', 'iWEFJYkR', 'BCehjxAl', 'nqndbwXP', \n",
    "                 'phwExnuQ', 'SzUcfjnr', 'PXtHzrqw', 'CNkSTLvx', 'tHFrzjai', 'MKozKLvT', 'pjHvJhoZ', \n",
    "                 'zkbPtFyO', 'xZBEXWPR', 'dyGFeFAg', 'pKPTBZZq', 'bCYWWTxH', 'EQKKRGkR', 'cCsFudxF', \n",
    "                 'muIetHMK', 'ishdUooQ', 'ItpCDLDM', 'ptEAnCSs', 'orfSPOJX', 'OKMtkqdQ', 'qTginJts',\n",
    "                 'JzhdOhzb', 'THDtJuYh', 'jwEuQQve', 'rQAsGegu', 'kLkPtNnh', 'CtHqaXhY', 'FmSlImli', \n",
    "                 'TiwRslOh', 'PWShFLnY', 'lFExzVaF', 'IKqsuNvV', 'CqqwKRSn', 'YUExUvhq', 'yaHLJxDD', \n",
    "                 'qlZMvcWc', 'dqRtXzav', 'ktBqxSwa', 'GIMIxlmv', 'wKVwRQIp', 'UaXLYMMh', 'bKtkhUWD', \n",
    "                 'HhKXJWno', 'tAYCAXge', 'aWlBVrkK', 'cDkXTaWP', 'hnmsRSvN', 'GHmAeUhZ', 'BIofZdtd', \n",
    "                 'QZiSWCCB', 'CsGvKKBJ', 'OLpGAaEu', 'JCDeZBXq', 'HGPWuGlV', 'WuwrCsIY', 'AlDbXTlZ', \n",
    "                 'hhold_size', 'ukWqmeSS', 'ukWqmeSS_max', 'ukWqmeSS_min', 'mOlYV_ind_x', 'msICg_ind_x', \n",
    "                 'YXCNt_ind_x', 'HgfUG_ind_x', 'EaHvf_ind_x', 'pdgUV_ind_x', 'xrEKh_ind_x', 'QkRds_ind_x', \n",
    "                 'XNPgB_ind_x', 'vvXmD_ind_x', 'KOjYm_ind_x', 'Qydia_ind_x', 'vtkRP_ind_x', 'RPBUw_ind_x', \n",
    "                 'QQdHS_ind_x', 'Hikoa_ind_x', 'SlRmt_ind_y', 'TRFeI_ind_y', 'fmdsF_ind_y', 'lBMrM_ind_y', \n",
    "                 'tMiQp_ind_y', 'wWIzo_ind_y', 'xnnDH_ind_y', 'CXizI_ind_y', 'DQhEE_ind_y', 'LvUxT_ind_y', \n",
    "                 'SSvEP_ind_y', 'YsahA_ind_y', 'lzzev_ind_y', 'ccbZA_ind_y', 'fOUHD_ind_y', 'vkRKJ_ind_y', \n",
    "                 'rwCRh_ind_y', 'yomtK_ind_y', 'iWGMu_ind_y', 'EaHvf_ind_y', 'GmSKW_ind_y', 'tymHY_ind_y', \n",
    "                 'yhUHu_ind_y', 'pdgUV_ind_y', 'qIbMY_ind_y', 'sDvAm_ind_y', 'bszTA_ind_y', 'veBMo_ind_y', \n",
    "                 'SowpV_ind_y', 'OeQKE_ind_y', 'XNPgB_ind_y', 'MxNAc_ind_y', 'SuzRU_ind_y', 'PmhpI_ind_y', \n",
    "                 'SjaWF_ind_y', 'TUafC_ind_y', 'bazjA_ind_y', 'dpMMl_ind_y', 'qVwNL_ind_y', 'zTqjB_ind_y', \n",
    "                 'BNylo_ind_y', 'CXjLj_ind_y', 'PwkMV_ind_y', 'Qydia_ind_y', 'kVYrO_ind_y', 'VneGw_ind_y', \n",
    "                 'rXEFU_ind_y', 'aKoLM_ind_y', 'SWhXf_ind_y', 'UCsCT_ind_y', 'uJdwX_ind_y', 'qmOVd_ind_y', \n",
    "                 'yOwsR_ind_y', 'ZIrnY_ind_y', 'dAmhs_ind_y', 'gCSRj_ind_y', 'ESfgE_ind_y', 'okwnE_ind_y', \n",
    "                 'OkXob_ind_y', 'dDnIb_ind_y', 'jVHyH_ind_y', 'xUYIC_ind_y']\n",
    "    \n",
    "    \n",
    "    Cfeatures = ['vmKoAlVH', 'LhUIIEHQ', 'KIUzCiTC', 'NONtAKOM',  'zyABXhnz', 'gUzYYakV', 'FlsGEbwx', \n",
    "                 'WdGBOpdZ', 'kLAQgdly', 'TusIlNXO', 'tPfjVDpu', 'EQtGHLFz', 'gLDyDXsb', 'xFKmUXhu', \n",
    "                 'oniXaptE', 'QUnDQaUl', 'ubefFytO', 'zLrQXqVU', 'coFdvtHB', 'yBSpOoNe', 'wpgRhUno', \n",
    "                 'XYfcLBql', 'pQGrypBw', 'DBjxSUvf', 'avZMPHry', 'HDZTYhoE', 'wcNjwEuQ', 'phbxKGlB', \n",
    "                 'HNRJQbcm', 'GJGfnAWg', 'tIeYAnmc', 'LwKcZtLN', 'nRXRObKS', 'DMslsIBE', 'AJHrHUkH', \n",
    "                 'ihACfisf', 'obIQUcpS', 'mmoCpqWS', 'XKQWlRjk_max', 'vWNISgEA_max', 'XKQWlRjk_min', \n",
    "                 'bsMfXBld_min', 'xqUoo_ind_x', 'amOeQ_ind_x', 'RxYsa_ind_x', 'ucHNS_ind_x', 'GHDuu_ind_x', \n",
    "                 'dxzZA_ind_x', 'DGWjH_ind_x', 'XvXON_ind_x', 'LuEXv_ind_x', 'hRHpW_ind_x', 'kvMGu_ind_x', \n",
    "                 'rAwcc_ind_x', 'vtkRP_ind_x', 'xgpHA_ind_x', 'xRxWC_ind_x', 'BZKME_ind_y', 'uSuzR_ind_y', \n",
    "                 'izIlz_ind_y', 'lJvCX_ind_y', 'bCSuY_ind_y', 'ALcKg_ind_y', 'FoQcU_ind_y', 'GpnOQ_ind_y', \n",
    "                 'vhhVz_ind_y', 'EGPlQ_ind_y', 'EhzOz_ind_y', 'MyWVa_ind_y', 'UrHEJ_ind_y', 'ehUOC_ind_y', \n",
    "                 'gRXcL_ind_y', 'JnveI_ind_y', 'KEvSa_ind_y', 'hAGot_ind_y', 'Iwnmb_ind_y', 'tPmhp_ind_y', \n",
    "                 'ucqiX_ind_y', 'mlNXN_ind_y', 'niWGM_ind_y', 'qQkRd_ind_y', 'sMBUT_ind_y', 'yWhop_ind_y', \n",
    "                 'JskzT_ind_y', 'cPXrX_ind_y', 'yFSGe_ind_y', 'wsHHy_ind_y', 'hOlGY_ind_y', 'bgZsP_ind_y', \n",
    "                 'xyraV_ind_y', 'EPnnG_ind_y', 'pClPr_ind_y', 'FeIwW_ind_y', 'Izoay_ind_y', 'gvqxs_ind_y', \n",
    "                 'MZyJF_ind_y', 'QrjGn_ind_y', 'iuiyo_ind_y', 'NBQEn_ind_y', 'Ysraf_ind_y', 'fZCQS_ind_y', \n",
    "                 'sitaC_ind_y', 'wZsYz_ind_y', 'QGHnL_ind_y', 'xgpHA_ind_y', 'kXobL_ind_y', 'oacjJ_ind_y', \n",
    "                 'xRxWC_ind_y']    \n",
    "   \n",
    "\n",
    "    aX_train = aX_train[Afeatures].copy()\n",
    "    aX_test = aX_test[Afeatures].copy()\n",
    "\n",
    "    cX_train = cX_train[Cfeatures].copy()\n",
    "    cX_test = cX_test[Cfeatures].copy()\n",
    "    print(\"--------------------------------------------\")\n",
    "    return aX_train, ay_train, aX_test, cX_train, cy_train, cX_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/texugo/anaconda3/envs/ag100/lib/python3.6/site-packages/ipykernel_launcher.py:18: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country A\n",
      "\n",
      "Country C\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "aX_train, aY_train, aX_test, cX_train, cY_train, cX_test = read_test_train_v2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Train/Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = {'A':'Keras_A01','B':'Keras_B01','C':'Keras_C01'}\n",
    "\n",
    "datafiles = {}\n",
    "datafiles['out'] = 'predictions/Keras_M03_F09_'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aX_train,aX_test,anum_list, acat_list, aDin, aDout = keras_encoding(aX_train,aX_test)\n",
    "\n",
    "#----------------------------------------------------------------\n",
    "varofint = cX_train.select_dtypes(['int64','float64']).keys()\n",
    "for v in varofint: \n",
    "    GX_train, GX_test =  make_Fx_numeric(cX_train[v].copy().values, cX_test[v].copy().values, cY_train)\n",
    "    cX_train[v+'_Fx'] = GX_train\n",
    "    cX_test[v+'_Fx'] = GX_test\n",
    "#----------------------------------------------------------------\n",
    "for v in varofint:\n",
    "    aux = pd.concat([cX_train[v],cX_test[v]], axis=0)\n",
    "    v2o = dict((j,i) for i,j in enumerate(np.sort(aux.unique())))\n",
    "    cX_train[v+'_Ox'] = cX_train[v].apply(lambda s: v2o[s]) \n",
    "    cX_test[v+'_Ox'] = cX_test[v].apply(lambda s: v2o[s])\n",
    "#----------------------------------------------------------------\n",
    "\n",
    "cX_train,cX_test,cnum_list, ccat_list, cDin, cDout = keras_encoding(cX_train,cX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_preds = eval(model['A'])(aX_train, aY_train, aX_test,anum_list, acat_list, aDin, aDout,0)\n",
    "c_preds = eval(model['C'])(cX_train, cY_train, cX_test,cnum_list, ccat_list, cDin, cDout,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert preds to data frames\n",
    "a_sub = make_country_df(a_preds.flatten(), aX_test, 'A')\n",
    "c_sub = make_country_df(c_preds.flatten(), cX_test, 'C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_sub.to_csv(datafiles['out']+'_A_test.csv')\n",
    "c_sub.to_csv(datafiles['out']+'_C_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5a94179780>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5a9408aeb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "df1 = pd.read_csv('./predictions/Keras_M03_F09__A_test.csv')\n",
    "df2 = pd.read_csv('./predictions/Keras_M03_F09__A_test_clean.csv')\n",
    "plt.plot(df1.poor, df2.poor, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
